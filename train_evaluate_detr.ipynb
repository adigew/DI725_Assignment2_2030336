{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fae139d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.49.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (3.5.0)\n",
      "Requirement already satisfied: wandb in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.18.7)\n",
      "Requirement already satisfied: pycocotools in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.0.8)\n",
      "Requirement already satisfied: filelock in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (5.29.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (6.1.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (2.19.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (78.1.0)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pycocotools) (3.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (6.3.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib>=2.1.0->pycocotools) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib>=2.1.0->pycocotools) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib>=2.1.0->pycocotools) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets wandb pycocotools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac762994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nesil.bor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# DI725 - Assignment 2: Object Detection with Hugging Face DETR + AU-AIR + WANDB\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import wandb\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa83518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:k830by2g) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">huggingface-detr-auair</strong> at: <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/k830by2g' target=\"_blank\">https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/k830by2g</a><br/> View project at: <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2' target=\"_blank\">https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250415_213813-k830by2g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:k830by2g). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\nesil.bor\\Desktop\\Folders\\master\\DI725\\DI725_Assignment2_2030336\\wandb\\run-20250415_214800-jyfc5nuq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/jyfc5nuq' target=\"_blank\">huggingface-detr-auair</a></strong> to <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2' target=\"_blank\">https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/jyfc5nuq' target=\"_blank\">https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/jyfc5nuq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 3.0062\n",
      "Epoch 2 - Loss: 3.0465\n",
      "Epoch 3 - Loss: 2.8998\n",
      "Epoch 4 - Loss: 2.8205\n",
      "Epoch 5 - Loss: 2.8491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Symlinked 3 files into the W&B run directory, call wandb.save again to sync new files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\nesil.bor\\\\Desktop\\\\Folders\\\\master\\\\DI725\\\\DI725_Assignment2_2030336\\\\wandb\\\\run-20250415_214800-jyfc5nuq\\\\files\\\\hf_detr_auair\\\\preprocessor_config.json',\n",
       " 'c:\\\\Users\\\\nesil.bor\\\\Desktop\\\\Folders\\\\master\\\\DI725\\\\DI725_Assignment2_2030336\\\\wandb\\\\run-20250415_214800-jyfc5nuq\\\\files\\\\hf_detr_auair\\\\model.safetensors',\n",
       " 'c:\\\\Users\\\\nesil.bor\\\\Desktop\\\\Folders\\\\master\\\\DI725\\\\DI725_Assignment2_2030336\\\\wandb\\\\run-20250415_214800-jyfc5nuq\\\\files\\\\hf_detr_auair\\\\config.json']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Paths\n",
    "root_dir = r\"C:\\Users\\nesil.bor\\Desktop\\Folders\\master\\DI725\\DI725_Assignment2_2030336\\data\\auair2019\"\n",
    "annotation_path = os.path.join(root_dir, \"annotations.json\")\n",
    "\n",
    "# Init WANDB\n",
    "wandb.init(project=\"di725-assignment2\", name=\"huggingface-detr-auair\")\n",
    "\n",
    "#  Load Processor + Model\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#  AU-AIR Dataset Class\n",
    "class AUAIRDetrDataset(Dataset):\n",
    "    def __init__(self, root, annotation_file):\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        self.annotations = data['annotations']\n",
    "        self.categories = data['categories']\n",
    "        self.img_dir = os.path.join(root, \"images\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ann = self.annotations[idx]\n",
    "        img_path = os.path.join(self.img_dir, ann[\"image_name\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        boxes, class_labels = [], []\n",
    "        annotations = []\n",
    "\n",
    "        for bbox in ann[\"bbox\"]:\n",
    "            x, y, w, h = bbox[\"left\"], bbox[\"top\"], bbox[\"width\"], bbox[\"height\"]\n",
    "            area = w * h\n",
    "            category_id = bbox[\"class\"] + 1  # +1 for DETR\n",
    "            \n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            class_labels.append(category_id)\n",
    "            \n",
    "            annotations.append({\n",
    "                \"bbox\": [x, y, w, h],\n",
    "                \"category_id\": category_id,\n",
    "                \"area\": area,\n",
    "                \"iscrowd\": 0\n",
    "                 })\n",
    "\n",
    "        encoding = processor(images=image, annotations={\n",
    "            \"image_id\": idx,\n",
    "            \"annotations\": annotations\n",
    "        }, return_tensors=\"pt\")\n",
    "\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
    "        target = encoding[\"labels\"][0]\n",
    "\n",
    "        return pixel_values, target\n",
    "\n",
    "#  Load dataset\n",
    "dataset = AUAIRDetrDataset(root_dir, annotation_path)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "#  Training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    for pixel_values, targets in loader:\n",
    "        pixel_values = torch.stack(pixel_values).to(device)\n",
    "        labels = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}\")\n",
    "    wandb.log({\"epoch\": epoch+1, \"loss\": avg_loss})\n",
    "\n",
    "#  Save model\n",
    "model.save_pretrained(\"hf_detr_auair\")\n",
    "processor.save_pretrained(\"hf_detr_auair\")\n",
    "wandb.save(\"hf_detr_auair/*\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32823/32823 [1:26:32<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=11.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=2.75s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
      "\n",
      "üìä Per-category AP (IoU=0.50:0.95):\n",
      "  Human               : 0.0009\n",
      "  Car                 : 0.0009\n",
      "  Truck               : 0.0000\n",
      "  Van                 : 0.0000\n",
      "  Motorbike           : 0.0000\n",
      "  Bicycle             : 0.0000\n",
      "  Bus                 : 0.0000\n",
      "  Trailer             : 0.0000\n",
      "‚úÖ mAP + per-class AP metrics logged to W&B.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AP50</td><td>‚ñÅ</td></tr><tr><td>AP75</td><td>‚ñÅ</td></tr><tr><td>AP_Bicycle</td><td>‚ñÅ</td></tr><tr><td>AP_Bus</td><td>‚ñÅ</td></tr><tr><td>AP_Car</td><td>‚ñÅ</td></tr><tr><td>AP_Human</td><td>‚ñÅ</td></tr><tr><td>AP_Motorbike</td><td>‚ñÅ</td></tr><tr><td>AP_Trailer</td><td>‚ñÅ</td></tr><tr><td>AP_Truck</td><td>‚ñÅ</td></tr><tr><td>AP_Van</td><td>‚ñÅ</td></tr><tr><td>AP_large</td><td>‚ñÅ</td></tr><tr><td>AP_medium</td><td>‚ñÅ</td></tr><tr><td>AP_small</td><td>‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà</td></tr><tr><td>loss</td><td>‚ñá‚ñà‚ñÉ‚ñÅ‚ñÇ</td></tr><tr><td>mAP@[0.5:0.95]</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AP50</td><td>0.00135</td></tr><tr><td>AP75</td><td>0.0001</td></tr><tr><td>AP_Bicycle</td><td>0</td></tr><tr><td>AP_Bus</td><td>0</td></tr><tr><td>AP_Car</td><td>0.00094</td></tr><tr><td>AP_Human</td><td>0.00089</td></tr><tr><td>AP_Motorbike</td><td>0</td></tr><tr><td>AP_Trailer</td><td>0</td></tr><tr><td>AP_Truck</td><td>0</td></tr><tr><td>AP_Van</td><td>0</td></tr><tr><td>AP_large</td><td>0.00089</td></tr><tr><td>AP_medium</td><td>0.00026</td></tr><tr><td>AP_small</td><td>0</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>2.84912</td></tr><tr><td>mAP@[0.5:0.95]</td><td>0.00032</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">huggingface-detr-auair</strong> at: <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/jyfc5nuq' target=\"_blank\">https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/jyfc5nuq</a><br/> View project at: <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2' target=\"_blank\">https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250415_214800-jyfc5nuq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "# ---------------------------\n",
    "#  COCO-Style Evaluation\n",
    "# ---------------------------\n",
    "\n",
    "def prepare_coco_format(dataset, output_path=\"gt.json\"):\n",
    "    coco_dict = {\"images\": [], \"annotations\": [], \"categories\": []}\n",
    "    ann_id = 1\n",
    "    for idx, ann in enumerate(dataset.annotations):\n",
    "        img_id = idx + 1\n",
    "        img_path = os.path.join(dataset.img_dir, ann[\"image_name\"])\n",
    "        with Image.open(img_path) as img:\n",
    "            width, height = img.size\n",
    "\n",
    "        coco_dict[\"images\"].append({\n",
    "            \"id\": img_id,\n",
    "            \"file_name\": ann[\"image_name\"],\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "        for box in ann[\"bbox\"]:\n",
    "            coco_dict[\"annotations\"].append({\n",
    "                \"id\": ann_id,\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": box[\"class\"] + 1,\n",
    "                \"bbox\": [box[\"left\"], box[\"top\"], box[\"width\"], box[\"height\"]],\n",
    "                \"area\": box[\"width\"] * box[\"height\"],\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "            ann_id += 1\n",
    "\n",
    "    for i, cat in enumerate(dataset.categories):\n",
    "        coco_dict[\"categories\"].append({\"id\": i + 1, \"name\": cat})\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(coco_dict, f)\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def run_inference_and_save_predictions(model, dataset, processor, device, output_path=\"pred.json\"):\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        ann = dataset.annotations[idx]\n",
    "        img_path = os.path.join(dataset.img_dir, ann[\"image_name\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        width, height = image.size\n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        target_sizes = torch.tensor([[height, width]]).to(device)\n",
    "        results_ = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.5)[0]\n",
    "\n",
    "        for i in range(len(results_[\"scores\"])):\n",
    "            box = results_[\"boxes\"][i]\n",
    "            score = results_[\"scores\"][i].item()\n",
    "            label = results_[\"labels\"][i].item()\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            results.append({\n",
    "                \"image_id\": idx + 1,\n",
    "                \"category_id\": label,\n",
    "                \"bbox\": [float(xmin), float(ymin), float(xmax - xmin), float(ymax - ymin)],\n",
    "                \"score\": float(score)\n",
    "            })\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def evaluate_map(gt_path, pred_path):\n",
    "    coco_gt = COCO(gt_path)\n",
    "    coco_dt = coco_gt.loadRes(pred_path)\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    metrics = {\n",
    "        \"mAP@[0.5:0.95]\": coco_eval.stats[0],\n",
    "        \"AP50\": coco_eval.stats[1],\n",
    "        \"AP75\": coco_eval.stats[2],\n",
    "        \"AP_small\": coco_eval.stats[3],\n",
    "        \"AP_medium\": coco_eval.stats[4],\n",
    "        \"AP_large\": coco_eval.stats[5]\n",
    "    }\n",
    "\n",
    "    # Per-category AP\n",
    "    precisions = coco_eval.eval['precision']\n",
    "    cat_ids = coco_gt.getCatIds()\n",
    "    categories = coco_gt.loadCats(cat_ids)\n",
    "\n",
    "    print(\"\\n Per-category AP (IoU=0.50:0.95):\")\n",
    "    for idx, cat in enumerate(categories):\n",
    "        precision = precisions[:, :, idx, 0, 0]\n",
    "        precision = precision[precision > -1]\n",
    "        ap = precision.mean() if precision.size > 0 else float('nan')\n",
    "        metrics[f\"AP_{cat['name']}\"] = ap\n",
    "        print(f\"  {cat['name']:20s}: {ap:.4f}\")\n",
    "\n",
    "    wandb.log(metrics)\n",
    "    print(\" mAP + per-class AP metrics logged to W&B.\")\n",
    "    return metrics\n",
    "\n",
    "# ---------------------------\n",
    "#  Run Evaluation\n",
    "# ---------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "gt_json = prepare_coco_format(dataset)\n",
    "pred_json = run_inference_and_save_predictions(model, dataset, processor, device)\n",
    "evaluate_map(gt_json, pred_json)\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e26c46",
   "metadata": {},
   "source": [
    "OPTIMIZATION\n",
    "\n",
    "Backbone freezing ‚Äì speeds up training and helps avoid overfitting on small datasets.\n",
    "\n",
    "Image resizing ‚Äì reduces compute and memory usage.\n",
    "\n",
    "Mixed precision training ‚Äì uses torch.cuda.amp for faster and memory-efficient training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630af625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:yl72xwnk) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hf-detr-auair-optimized</strong> at: <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/yl72xwnk' target=\"_blank\">https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/yl72xwnk</a><br/> View project at: <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2' target=\"_blank\">https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250416_132756-yl72xwnk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:yl72xwnk). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\nesil.bor\\Desktop\\Folders\\master\\DI725\\DI725_Assignment2_2030336\\wandb\\run-20250416_133247-znszvrac</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/znszvrac' target=\"_blank\">hf-detr-auair-optimized</a></strong> to <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2' target=\"_blank\">https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/znszvrac' target=\"_blank\">https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/znszvrac</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\nesil.bor\\AppData\\Local\\Temp\\ipykernel_28756\\2112435702.py:71: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 2.1709\n",
      "Epoch 2 - Loss: 1.8471\n",
      "Epoch 3 - Loss: 1.7209\n",
      "Epoch 4 - Loss: 1.6756\n",
      "Epoch 5 - Loss: 1.5982\n",
      "Epoch 6 - Loss: 1.6798\n",
      "Epoch 7 - Loss: 1.6488\n",
      "Epoch 8 - Loss: 1.7808\n",
      "Epoch 9 - Loss: 1.7906\n",
      "Epoch 10 - Loss: 1.8217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Symlinked 3 files into the W&B run directory, call wandb.save again to sync new files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\nesil.bor\\\\Desktop\\\\Folders\\\\master\\\\DI725\\\\DI725_Assignment2_2030336\\\\wandb\\\\run-20250416_133247-znszvrac\\\\files\\\\hf_detr_auair_optimized\\\\config.json',\n",
       " 'c:\\\\Users\\\\nesil.bor\\\\Desktop\\\\Folders\\\\master\\\\DI725\\\\DI725_Assignment2_2030336\\\\wandb\\\\run-20250416_133247-znszvrac\\\\files\\\\hf_detr_auair_optimized\\\\model.safetensors',\n",
       " 'c:\\\\Users\\\\nesil.bor\\\\Desktop\\\\Folders\\\\master\\\\DI725\\\\DI725_Assignment2_2030336\\\\wandb\\\\run-20250416_133247-znszvrac\\\\files\\\\hf_detr_auair_optimized\\\\preprocessor_config.json']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import wandb\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "from torchvision.transforms import Resize\n",
    "from torch.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "#  Paths\n",
    "root_dir = r\"C:\\Users\\nesil.bor\\Desktop\\Folders\\master\\DI725\\DI725_Assignment2_2030336\\data\\auair2019\"\n",
    "annotation_path = os.path.join(root_dir, \"annotations.json\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#  Init W&B\n",
    "wandb.init(project=\"di725-assignment2\", name=\"hf-detr-auair-optimized\")\n",
    "\n",
    "#  Load Model + Processor (swap with tiny model if needed)\n",
    "model_name = \"facebook/detr-resnet-50\"  # or try \"facebook/detr-resnet-50\" (official tiny is not yet on HF)\n",
    "processor = DetrImageProcessor.from_pretrained(model_name)\n",
    "model = DetrForObjectDetection.from_pretrained(model_name).to(device)\n",
    "\n",
    "#  Freeze Backbone\n",
    "for name, param in model.model.backbone.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#  Dataset\n",
    "class AUAIRDetrDataset(Dataset):\n",
    "    def __init__(self, root, annotation_file, image_size=(384, 384)):\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        self.annotations = data['annotations']\n",
    "        self.img_dir = os.path.join(root, \"images\")\n",
    "        self.resize = Resize(image_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ann = self.annotations[idx]\n",
    "        img_path = os.path.join(self.img_dir, ann[\"image_name\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.resize(image)\n",
    "\n",
    "        annotations = []\n",
    "        for bbox in ann[\"bbox\"]:\n",
    "            x, y, w, h = bbox[\"left\"], bbox[\"top\"], bbox[\"width\"], bbox[\"height\"]\n",
    "            category_id = bbox[\"class\"] + 1  # DETR expects non-zero class ids\n",
    "            annotations.append({\n",
    "                \"bbox\": [x, y, w, h],\n",
    "                \"category_id\": category_id,\n",
    "                \"area\": w * h,\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "\n",
    "        encoding = processor(images=image, annotations={\n",
    "            \"image_id\": idx,\n",
    "            \"annotations\": annotations\n",
    "        }, return_tensors=\"pt\")\n",
    "\n",
    "        return encoding[\"pixel_values\"].squeeze(), encoding[\"labels\"][0]\n",
    "\n",
    "#  Dataloader\n",
    "dataset = AUAIRDetrDataset(root_dir, annotation_path)\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "#  Training Loop (with mixed precision)\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "scaler = GradScaler()\n",
    "model.train()\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for pixel_values, targets in loader:\n",
    "        pixel_values = torch.stack(pixel_values).to(device)\n",
    "        labels = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type=device):\n",
    "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}\")\n",
    "    wandb.log({\"epoch\": epoch+1, \"loss\": avg_loss})\n",
    "\n",
    "#  Save Model\n",
    "model.save_pretrained(\"hf_detr_auair_optimized\")\n",
    "processor.save_pretrained(\"hf_detr_auair_optimized\")\n",
    "wandb.save(\"hf_detr_auair_optimized/*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae490ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetrForObjectDetection(\n",
       "  (model): DetrModel(\n",
       "    (backbone): DetrConvModel(\n",
       "      (conv_encoder): DetrConvEncoder(\n",
       "        (model): FeatureListNet(\n",
       "          (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (bn1): DetrFrozenBatchNorm2d()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (layer1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer3): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (4): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (5): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer4): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (position_embedding): DetrSinePositionEmbedding()\n",
       "    )\n",
       "    (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (query_position_embeddings): Embedding(100, 256)\n",
       "    (encoder): DetrEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x DetrEncoderLayer(\n",
       "          (self_attn): DetrAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): DetrDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x DetrDecoderLayer(\n",
       "          (self_attn): DetrAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): DetrAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (class_labels_classifier): Linear(in_features=256, out_features=92, bias=True)\n",
       "  (bbox_predictor): DetrMLPPredictionHead(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "\n",
    "#  Reload optimized weights before evaluation\n",
    "model = DetrForObjectDetection.from_pretrained(\"hf_detr_auair_optimized\").to(device)\n",
    "processor = DetrImageProcessor.from_pretrained(\"hf_detr_auair_optimized\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49886257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import wandb\n",
    "import torch\n",
    "import os\n",
    "\n",
    "#  1. Save GT in COCO Format\n",
    "def prepare_coco_format(dataset, output_path=\"gt.json\"):\n",
    "    coco_dict = {\"images\": [], \"annotations\": [], \"categories\": []}\n",
    "    ann_id = 1\n",
    "    for idx, ann in enumerate(dataset.annotations):\n",
    "        img_id = idx + 1\n",
    "        img_path = os.path.join(dataset.img_dir, ann[\"image_name\"])\n",
    "        with Image.open(img_path) as img:\n",
    "            width, height = img.size\n",
    "\n",
    "        coco_dict[\"images\"].append({\n",
    "            \"id\": img_id,\n",
    "            \"file_name\": ann[\"image_name\"],\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "        for box in ann[\"bbox\"]:\n",
    "            coco_dict[\"annotations\"].append({\n",
    "                \"id\": ann_id,\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": box[\"class\"] + 1,\n",
    "                \"bbox\": [box[\"left\"], box[\"top\"], box[\"width\"], box[\"height\"]],\n",
    "                \"area\": box[\"width\"] * box[\"height\"],\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "            ann_id += 1\n",
    "\n",
    "    for i in range(1, 9):  # AU-AIR has 8 categories\n",
    "        coco_dict[\"categories\"].append({\"id\": i, \"name\": f\"class_{i}\"})\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(coco_dict, f)\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "#  2. Run Inference\n",
    "def run_inference_and_save_predictions(model, dataset, processor, device, output_path=\"pred.json\"):\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        ann = dataset.annotations[idx]\n",
    "        img_path = os.path.join(dataset.img_dir, ann[\"image_name\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        width, height = image.size\n",
    "\n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        #  Lower the threshold from 0.5 to 0.001\n",
    "        target_sizes = torch.tensor([[height, width]]).to(device)\n",
    "        results_ = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.001)[0]\n",
    "\n",
    "        #  Add predictions if any exist\n",
    "        if len(results_[\"scores\"]) == 0:\n",
    "            continue\n",
    "\n",
    "        for i in range(len(results_[\"scores\"])):\n",
    "            box = results_[\"boxes\"][i]\n",
    "            score = results_[\"scores\"][i].item()\n",
    "            label = results_[\"labels\"][i].item()\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            results.append({\n",
    "                \"image_id\": idx + 1,\n",
    "                \"category_id\": label,\n",
    "                \"bbox\": [float(xmin), float(ymin), float(xmax - xmin), float(ymax - ymin)],\n",
    "                \"score\": float(score)\n",
    "            })\n",
    "\n",
    "    #  Debugging check\n",
    "    print(f\" Total predictions saved: {len(results)}\")\n",
    "    if len(results) == 0:\n",
    "        print(\" Warning: No predictions were generated. Try lowering the threshold or checking the model output.\")\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "\n",
    "#  3. Evaluate mAP\n",
    "def evaluate_map(gt_path, pred_path):\n",
    "    coco_gt = COCO(gt_path)\n",
    "    coco_dt = coco_gt.loadRes(pred_path)\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    metrics = {\n",
    "        \"mAP@[0.5:0.95]\": coco_eval.stats[0],\n",
    "        \"AP50\": coco_eval.stats[1],\n",
    "        \"AP75\": coco_eval.stats[2],\n",
    "        \"AP_small\": coco_eval.stats[3],\n",
    "        \"AP_medium\": coco_eval.stats[4],\n",
    "        \"AP_large\": coco_eval.stats[5]\n",
    "    }\n",
    "\n",
    "    # Per-category AP\n",
    "    precisions = coco_eval.eval['precision']\n",
    "    cat_ids = coco_gt.getCatIds()\n",
    "    categories = coco_gt.loadCats(cat_ids)\n",
    "\n",
    "    print(\"\\n Per-category AP (IoU=0.50:0.95):\")\n",
    "    for idx, cat in enumerate(categories):\n",
    "        precision = precisions[:, :, idx, 0, 0]\n",
    "        precision = precision[precision > -1]\n",
    "        ap = precision.mean() if precision.size > 0 else float('nan')\n",
    "        metrics[f\"AP_{cat['name']}\"] = ap\n",
    "        print(f\"  {cat['name']:20s}: {ap:.4f}\")\n",
    "\n",
    "    wandb.log(metrics)\n",
    "    print(\" mAP + per-class AP metrics logged to W&B.\")\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b593dea",
   "metadata": {},
   "source": [
    "gt.json: ground truth in COCO format\n",
    "\n",
    "pred.json: DETR predictions formatted for COCOEval\n",
    "\n",
    "Console summary with mAP + per-class AP\n",
    "\n",
    "Results logged to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed270c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32823/32823 [1:51:07<00:00,  4.92it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total predictions saved: 3282300\n",
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=16.36s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=152.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=33.74s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\n",
      "üìä Per-category AP (IoU=0.50:0.95):\n",
      "  class_1             : 0.0000\n",
      "  class_2             : 0.0000\n",
      "  class_3             : 0.0000\n",
      "  class_4             : 0.0000\n",
      "  class_5             : 0.0000\n",
      "  class_6             : 0.0000\n",
      "  class_7             : 0.0000\n",
      "  class_8             : 0.0000\n",
      "‚úÖ mAP + per-class AP metrics logged to W&B.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AP50</td><td>‚ñÅ</td></tr><tr><td>AP75</td><td>‚ñÅ</td></tr><tr><td>AP_class_1</td><td>‚ñÅ</td></tr><tr><td>AP_class_2</td><td>‚ñÅ</td></tr><tr><td>AP_class_3</td><td>‚ñÅ</td></tr><tr><td>AP_class_4</td><td>‚ñÅ</td></tr><tr><td>AP_class_5</td><td>‚ñÅ</td></tr><tr><td>AP_class_6</td><td>‚ñÅ</td></tr><tr><td>AP_class_7</td><td>‚ñÅ</td></tr><tr><td>AP_class_8</td><td>‚ñÅ</td></tr><tr><td>AP_large</td><td>‚ñÅ</td></tr><tr><td>AP_medium</td><td>‚ñÅ</td></tr><tr><td>AP_small</td><td>‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà</td></tr><tr><td>loss</td><td>‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ</td></tr><tr><td>mAP@[0.5:0.95]</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AP50</td><td>0.0</td></tr><tr><td>AP75</td><td>0</td></tr><tr><td>AP_class_1</td><td>0</td></tr><tr><td>AP_class_2</td><td>0.0</td></tr><tr><td>AP_class_3</td><td>0</td></tr><tr><td>AP_class_4</td><td>0</td></tr><tr><td>AP_class_5</td><td>0</td></tr><tr><td>AP_class_6</td><td>0</td></tr><tr><td>AP_class_7</td><td>0</td></tr><tr><td>AP_class_8</td><td>0</td></tr><tr><td>AP_large</td><td>0.0</td></tr><tr><td>AP_medium</td><td>0</td></tr><tr><td>AP_small</td><td>0</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>1.82166</td></tr><tr><td>mAP@[0.5:0.95]</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hf-detr-auair-optimized</strong> at: <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/znszvrac' target=\"_blank\">https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2/runs/znszvrac</a><br/> View project at: <a href='https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2' target=\"_blank\">https://wandb.ai/adigew-middle-east-technical-university/di725-assignment2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250416_133247-znszvrac\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Final evaluation run\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "gt_json = prepare_coco_format(dataset)\n",
    "pred_json = run_inference_and_save_predictions(model, dataset, processor, device)\n",
    "evaluate_map(gt_json, pred_json)\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29a6a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e8889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1eab90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
